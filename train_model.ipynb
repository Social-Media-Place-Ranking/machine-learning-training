{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import pymongo\n",
    "import dns\n",
    "import json\n",
    "from nltk.sentiment import SentimentAnalyzer\n",
    "import haversine as hs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### read the query-doc JSON file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the directory path\n",
    "path_to_json = '/Users/emadarmiti/Desktop/cap-s5/places_ranking/es_qureries/'\n",
    "\n",
    "# define the query-document json file \n",
    "query_doc = json.loads('{}')\n",
    "\n",
    "# get all json files that exist in the directory\n",
    "for file_path in os.listdir(path_to_json):\n",
    "    \n",
    "    if file_path.endswith('.json'):\n",
    "        \n",
    "        # open the json file \n",
    "        with open(os.path.join(path_to_json,file_path)) as json_file:\n",
    "            \n",
    "            # append the json file, to get all of them in on json variable\n",
    "            query_doc.update(json.load(json_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23079"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(query_doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### connect to MongoDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "def connect_mongodb(mongoDB_url, database_name, collection_name):\n",
    "    \"\"\"connect to the mongoDB \n",
    "\n",
    "    Args:\n",
    "        mongoDB_url : mongoDB endpoint url\n",
    "        database_name : database name\n",
    "        collection_name : collection name\n",
    "\n",
    "    Returns:\n",
    "        the database collection object\n",
    "    \"\"\"\n",
    "\n",
    "    # create mongodb client\n",
    "    mongoDB_client = pymongo.MongoClient(mongoDB_url)\n",
    "    \n",
    "    # get the database\n",
    "    tweets_database = mongoDB_client[database_name]\n",
    "\n",
    "    # get the collection\n",
    "    tweets_collection = tweets_database[collection_name]\n",
    "    \n",
    "    # return the collection object\n",
    "    return tweets_collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the mongoDB endpoint\n",
    "mongodb_url = \"mongodb://rama:rama@cluster0-shard-00-00.xlj8q.mongodb.net:27017,cluster0-shard-00-01.xlj8q.mongodb.net:27017,cluster0-shard-00-02.xlj8q.mongodb.net:27017/tweets?ssl=true&replicaSet=atlas-yi054u-shard-0&authSource=admin&retryWrites=true&w=majority\"\n",
    "\n",
    "# connect to the database\n",
    "tweets_collection = connect_mongodb(mongodb_url, \"tweets\", \"tweets2018\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### find the tweets that near to the documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_tweets_near_place(coordinates):\n",
    "    \"\"\"find the tweets within 100m radius from the passed coordinates\n",
    "\n",
    "    Args:\n",
    "       coordinates : lon,lat for the central point\n",
    "\n",
    "    Returns:\n",
    "        extracted info from the tweets\n",
    "    \"\"\"\n",
    "    \n",
    "    # define the body of the query\n",
    "    myquery =  [\n",
    "        \n",
    "      { \"$geoNear\": {\n",
    "          \n",
    "             \"near\": { \"type\": \"Point\", \"coordinates\": coordinates },\n",
    "             \"distanceField\": \"place.coordinates\",\n",
    "             \"maxDistance\": 100}}\n",
    "        \n",
    "        \n",
    "    ,{  \"$group\": { \n",
    "        \n",
    "            \"_id\": None,\n",
    "            \"tweets_count\": { \"$sum\": 1 },\n",
    "            \"tweets_average_length\" : { \"$avg\" : {\"$strLenCP\" : \"$tweet\"}},\n",
    "            \"replies_count\": { \"$sum\": \"replies_count\"},\n",
    "            \"retweets_count\": { \"$sum\": \"retweets_count\"}, \n",
    "            \"likes_count\": { \"$sum\": \"likes_count\"},\n",
    "            \"hashtags\": { \"$sum\": {\"$size\" : \"$hashtags\"}},\n",
    "            \"mentions\": { \"$sum\": {\"$size\" : \"$mentions\"}}}}]\n",
    "\n",
    "    # send the query and return the results\n",
    "    return list(tweets_collection.aggregate(myquery))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### build the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_dataset(documents, query, user_location):\n",
    "    \n",
    "    # define the list result of the documents data\n",
    "    documents_data = []\n",
    "    \n",
    "    # go over each document and gather its info\n",
    "    for doc in documents:\n",
    "       \n",
    "        # slice the location of the document\n",
    "        coordinates = list(doc['_source']['location'].values())\n",
    "        \n",
    "        # create two tuples of coordinates\n",
    "        tweet_loc = (coordinates[0], coordinates[1])\n",
    "        user_loc = (user_location[0], user_location[1])\n",
    "\n",
    "        # get the distance between the user and the document\n",
    "        distance = hs.haversine(tweet_loc,user_loc)\n",
    "        \n",
    "        # get the tweets\n",
    "        tweets = find_tweets_near_place(coordinates)\n",
    "        \n",
    "        # neglect the doc that don't have tweets\n",
    "        if len(tweets):\n",
    "            \n",
    "            # define the dict for the document\n",
    "            doc_data = {\"query\" : query, \"document\" : doc['_source']['name'],\n",
    "                        \"query_length\" : len(query), \"document_length\" : len(doc['_source']['name']),\n",
    "                        \"elasticsearch_score\" : doc['_score'],\n",
    "                         \"distance\" : distance}\n",
    "            \n",
    "            \n",
    "            # add the tweets info\n",
    "            doc_data.update(tweets[0])\n",
    "            \n",
    "            # append the doc dict to the list result\n",
    "            documents_data.append(doc_data)\n",
    "    \n",
    "    # return the documents data\n",
    "    return documents_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the result dict for all query-doc \n",
    "tweets_query_doc = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "# go over each query-doc and use the previous function to get the tweets info from the MongoDB\n",
    "for query in list(query_doc.keys())[:3]:\n",
    "    \n",
    "    # build the dataset for one query\n",
    "    query_doc_data = build_dataset(query_doc[query], query, [-40.08022, 143.60315])\n",
    "    \n",
    "    # neglect the queries that don't have documents with tweets\n",
    "    if len(query_doc_data):\n",
    "        tweets_query_doc.extend(query_doc_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.json_normalize(tweets_query_doc)\n",
    "data = data.drop('_id', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query</th>\n",
       "      <th>document</th>\n",
       "      <th>query_length</th>\n",
       "      <th>document_length</th>\n",
       "      <th>elasticsearch_score</th>\n",
       "      <th>distance</th>\n",
       "      <th>tweets_count</th>\n",
       "      <th>tweets_average_length</th>\n",
       "      <th>replies_count</th>\n",
       "      <th>retweets_count</th>\n",
       "      <th>likes_count</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>mentions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dix/Adler</td>\n",
       "      <td>Johnathan Adler</td>\n",
       "      <td>9</td>\n",
       "      <td>15</td>\n",
       "      <td>10.596428</td>\n",
       "      <td>16859.274007</td>\n",
       "      <td>17</td>\n",
       "      <td>75.117647</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dix/Adler</td>\n",
       "      <td>Jonathan Adler</td>\n",
       "      <td>9</td>\n",
       "      <td>14</td>\n",
       "      <td>10.596423</td>\n",
       "      <td>16857.821001</td>\n",
       "      <td>30</td>\n",
       "      <td>76.233333</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Downt</td>\n",
       "      <td>Up &amp; Down</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>7.047873</td>\n",
       "      <td>16854.983642</td>\n",
       "      <td>151</td>\n",
       "      <td>73.973510</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Downt</td>\n",
       "      <td>Dont know</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>7.047838</td>\n",
       "      <td>16855.487413</td>\n",
       "      <td>66</td>\n",
       "      <td>74.681818</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Downt</td>\n",
       "      <td>Chau Down</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>7.047823</td>\n",
       "      <td>16855.730196</td>\n",
       "      <td>43</td>\n",
       "      <td>75.023256</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       query         document  query_length  document_length  \\\n",
       "0  Dix/Adler  Johnathan Adler             9               15   \n",
       "1  Dix/Adler   Jonathan Adler             9               14   \n",
       "2      Downt        Up & Down             5                9   \n",
       "3      Downt        Dont know             5                9   \n",
       "4      Downt        Chau Down             5                9   \n",
       "\n",
       "   elasticsearch_score      distance  tweets_count  tweets_average_length  \\\n",
       "0            10.596428  16859.274007            17              75.117647   \n",
       "1            10.596423  16857.821001            30              76.233333   \n",
       "2             7.047873  16854.983642           151              73.973510   \n",
       "3             7.047838  16855.487413            66              74.681818   \n",
       "4             7.047823  16855.730196            43              75.023256   \n",
       "\n",
       "   replies_count  retweets_count  likes_count  hashtags  mentions  \n",
       "0              0               0            0         0        10  \n",
       "1              0               0            0         0        22  \n",
       "2              0               0            0         3        83  \n",
       "3              0               0            0         0        32  \n",
       "4              0               0            0         0        18  "
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['query', 'document', 'query_length', 'document_length',\n",
       "       'elasticsearch_score', 'distance', 'tweets_count',\n",
       "       'tweets_average_length', 'replies_count', 'retweets_count',\n",
       "       'likes_count', 'hashtags', 'mentions'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data.to_csv('/Users/emadarmiti/Desktop/cap-s5/places_ranking/row_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### build the dataframe "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### save the query-doc-tweets into a JSON file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tf-idf?\n",
    "# should we delete non tweets doc?\n",
    "# why just two featrues in labeling?\n",
    "# hashtags\n",
    "# query/document length\n",
    "# nlp\n",
    "# tweets average length\n",
    "# mentions - boolean\n",
    "## label = nlp + distance + elasicsearch + tweets?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
