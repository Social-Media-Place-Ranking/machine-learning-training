{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import pymongo\n",
    "import dns\n",
    "import json\n",
    "from nltk.sentiment import SentimentAnalyzer\n",
    "import haversine as hs\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import random\n",
    "import sys\n",
    "import math\n",
    "from random import randrange\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### read the query-doc JSON file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the directory path\n",
    "path_to_json = '/Users/emadarmiti/Desktop/cap-s5/places_ranking/es_qureries/'\n",
    "\n",
    "# define the query-document json file \n",
    "query_doc = json.loads('{}')\n",
    "\n",
    "# get all json files that exist in the directory\n",
    "for file_path in os.listdir(path_to_json):\n",
    "    \n",
    "    if file_path.endswith('.json'):\n",
    "        \n",
    "        # open the json file \n",
    "        with open(os.path.join(path_to_json,file_path)) as json_file:\n",
    "            \n",
    "            # append the json file, to get all of them in on json variable\n",
    "            query_doc.update(json.load(json_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23079"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(query_doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### connect to MongoDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def connect_mongodb(mongoDB_url, database_name, collection_name):\n",
    "    \"\"\"connect to the mongoDB \n",
    "\n",
    "    Args:\n",
    "        mongoDB_url : mongoDB endpoint url\n",
    "        database_name : database name\n",
    "        collection_name : collection name\n",
    "\n",
    "    Returns:\n",
    "        the database collection object\n",
    "    \"\"\"\n",
    "\n",
    "    # create mongodb client\n",
    "    mongoDB_client = pymongo.MongoClient(mongoDB_url)\n",
    "    \n",
    "    # get the database\n",
    "    tweets_database = mongoDB_client[database_name]\n",
    "\n",
    "    # get the collection\n",
    "    tweets_collection = tweets_database[collection_name]\n",
    "    \n",
    "    # return the collection object\n",
    "    return tweets_collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the mongoDB endpoint\n",
    "mongodb_url = \"mongodb://rama:rama@cluster0-shard-00-00.xlj8q.mongodb.net:27017,cluster0-shard-00-01.xlj8q.mongodb.net:27017,cluster0-shard-00-02.xlj8q.mongodb.net:27017/tweets?ssl=true&replicaSet=atlas-yi054u-shard-0&authSource=admin&retryWrites=true&w=majority\"\n",
    "\n",
    "# connect to the database\n",
    "tweets_collection = connect_mongodb(mongodb_url, \"tweets\", \"tweetsFinal\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### find the tweets that near to the documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_tweets_near_place(coordinates):\n",
    "    \"\"\"find the tweets within 100m radius from the passed coordinates\n",
    "\n",
    "    Args:\n",
    "       coordinates : lon,lat for the central point\n",
    "\n",
    "    Returns:\n",
    "        extracted info from the tweets\n",
    "    \"\"\"\n",
    "    \n",
    "    # define the body of the query\n",
    "    myquery =  [\n",
    "        \n",
    "      { \"$geoNear\": {\n",
    "          \n",
    "             \"near\": { \"type\": \"Point\", \"coordinates\": coordinates },\n",
    "             \"distanceField\": \"place.coordinates\",\n",
    "             \"maxDistance\": 100}}\n",
    "        \n",
    "        \n",
    "    ,{  \"$group\": { \n",
    "        \n",
    "            \"_id\": None,\n",
    "            \"tweets_count\": { \"$sum\": 1 },\n",
    "            \"tweets_average_length\" : { \"$avg\" : {\"$strLenCP\" : \"$tweet\"}},\n",
    "            \"replies_count\": { \"$sum\": \"replies_count\"},\n",
    "            \"retweets_count\": { \"$sum\": \"retweets_count\"}, \n",
    "            \"likes_count\": { \"$sum\": \"likes_count\"},\n",
    "            \"popularity\": { \"$avg\": \"$popularity\"},\n",
    "            \"hashtags\": { \"$sum\": {\"$size\" : \"$hashtags\"}},\n",
    "            \"mentions\": { \"$sum\": {\"$size\" : \"$mentions\"}}}}]\n",
    "\n",
    "    # send the query and return the results\n",
    "    return list(tweets_collection.aggregate(myquery))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### build the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jaccard_similarity(list1, list2):\n",
    "    s1 = set(list1)\n",
    "    s2 = set(list2)\n",
    "    return float(len(s1.intersection(s2)) / len(s1.union(s2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_random_coordinates(coordinates, radius):\n",
    "                   \n",
    "    radiusInDegrees=radius/111300            \n",
    "    r = radiusInDegrees\n",
    "\n",
    "    u = float(random.uniform(0.0,1.0))\n",
    "    v = float(random.uniform(0.0,1.0))\n",
    "    w = r * math.sqrt(u)\n",
    "    t = 2 * math.pi * v\n",
    "    x = w * math.cos(t) \n",
    "    y = w * math.sin(t)\n",
    "\n",
    "    xLat  = x + coordinates[0]\n",
    "    yLong = y + coordinates[1]\n",
    "\n",
    "    return [xLat, yLong]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_dataset(documents, query):\n",
    "    \n",
    "    # get the coordinates for one document to get a random user lcation \n",
    "    temp_coordiates = list(documents[0]['_source']['location'].values())\n",
    "    \n",
    "    # get a random user location \n",
    "    user_location = get_random_coordinates(temp_coordiates, randrange(10))\n",
    "    \n",
    "    # define the list result of the documents data\n",
    "    documents_data = []\n",
    "    \n",
    "    # go over each document and gather its info\n",
    "    for doc in documents:\n",
    "       \n",
    "        # slice the location of the document\n",
    "        coordinates = list(doc['_source']['location'].values())\n",
    "        \n",
    "        \n",
    "        # get the tweets\n",
    "        tweets = find_tweets_near_place(coordinates)\n",
    "        \n",
    "        # neglect the doc that don't have tweets\n",
    "        if len(tweets):\n",
    "            \n",
    "            # get the document name\n",
    "            document = doc['_source']['name']\n",
    "            \n",
    "            # find the jaccard similarity\n",
    "            jaccard_entire = jaccard_similarity(query.split(\" \"), document.split(\" \"))\n",
    "            \n",
    "            # slice the first 3 characters and find the jaccard similaity\n",
    "            sub_query = [word[:3] for word in query.split(\" \")]\n",
    "            sub_document = [word[:3] for word in document.split(\" \")]\n",
    "            \n",
    "            sub_jaccard = jaccard_similarity(sub_query, sub_document)\n",
    "            \n",
    "            # check if the query and the document have the same prefix\n",
    "            prefix_match = query[:3] == document[:3]\n",
    "            \n",
    "            # create two tuples of coordinates\n",
    "            tweet_loc = (coordinates[0], coordinates[1])\n",
    "            user_loc = (user_location[0], user_location[1])\n",
    "\n",
    "            # get the distance between the user and the document(in meters)\n",
    "            distance = hs.haversine(tweet_loc,user_loc)\n",
    "            \n",
    "            # define the dict for the document\n",
    "            doc_data = {\"query\" : query,\n",
    "                        \"document\" : document,\n",
    "                        \"query_length\" : len(query),\n",
    "                        \"document_length\" : len(doc['_source']['name']),\n",
    "                        \"jaccard_entire\" : jaccard_entire,\n",
    "                        \"sub_jaccard\" : sub_jaccard,\n",
    "                        \"prefix_match\" : prefix_match,\n",
    "                        \"elasticsearch_score\" : doc['_score'],\n",
    "                        \"distance\" : distance}\n",
    "            \n",
    "            \n",
    "            # add the tweets info\n",
    "            doc_data.update(tweets[0])\n",
    "            \n",
    "            # append the doc dict to the list result\n",
    "            documents_data.append(doc_data)\n",
    "    \n",
    "    # return the documents data\n",
    "    return documents_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataframem empty\n",
    "data = pd.DataFrame(columns = ['query', 'document', 'query_length', 'document_length',\n",
    "       'jaccard_entire', 'sub_jaccard', 'prefix_match', 'elasticsearch_score',\n",
    "       'distance', 'tweets_count', 'tweets_average_length', 'replies_count',\n",
    "       'retweets_count', 'likes_count', 'popularity', 'hashtags', 'mentions']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaling(nubmers):\n",
    "    scale = preprocessing.minmax_scale(nubmers, feature_range = ((1, 2, 3, 4, 5)[-len(nubmers):][0],\n",
    "                                                           (1, 2, 3, 4, 5)[-len(nubmers):][-1]))\n",
    "    return np.around(scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "# go over each query-doc and use the previous function to get the tweets info from the MongoDB\n",
    "for query in list(query_doc.keys())[:10]:\n",
    "    \n",
    "    # build the dataset for one query\n",
    "    query_doc_data = build_dataset(query_doc[query], query)\n",
    "    \n",
    "    # neglect the queries that don't have documents with tweets\n",
    "    if len(query_doc_data):\n",
    "        \n",
    "        #create a small dataframe\n",
    "        data_sub = pd.json_normalize(query_doc_data)\n",
    "        data_sub = data_sub.drop('_id', 1)\n",
    "        \n",
    "        #add the socres\n",
    "        distance = np.array(data_sub['distance'])\n",
    "        jaccard = np.array(data_sub['sub_jaccard'])\n",
    "        \n",
    "        if len(distance) == 1:\n",
    "            data_sub['label'] = [5]\n",
    "            \n",
    "        else:\n",
    "            scaled_distance = scaling(-distance)\n",
    "            scaled_jaccard = scaling(jaccard)\n",
    "            \n",
    "            label =  np.array(1.1 * scaled_jaccard +  scaled_distance)\n",
    "        \n",
    "            data_sub['label'] = scaling(label)\n",
    "\n",
    "        #append to the original one\n",
    "        data = data.append(data_sub)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query</th>\n",
       "      <th>document</th>\n",
       "      <th>query_length</th>\n",
       "      <th>document_length</th>\n",
       "      <th>jaccard_entire</th>\n",
       "      <th>sub_jaccard</th>\n",
       "      <th>prefix_match</th>\n",
       "      <th>elasticsearch_score</th>\n",
       "      <th>distance</th>\n",
       "      <th>tweets_count</th>\n",
       "      <th>tweets_average_length</th>\n",
       "      <th>replies_count</th>\n",
       "      <th>retweets_count</th>\n",
       "      <th>likes_count</th>\n",
       "      <th>popularity</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>mentions</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dix/Adler</td>\n",
       "      <td>Johnathan Adler</td>\n",
       "      <td>9</td>\n",
       "      <td>15</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>10.596428</td>\n",
       "      <td>372.269962</td>\n",
       "      <td>17</td>\n",
       "      <td>75.117647</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.512406</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dix/Adler</td>\n",
       "      <td>Jonathan Adler</td>\n",
       "      <td>9</td>\n",
       "      <td>14</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>10.596423</td>\n",
       "      <td>372.302677</td>\n",
       "      <td>30</td>\n",
       "      <td>76.233333</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.612857</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Downt</td>\n",
       "      <td>Up &amp; Down</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>False</td>\n",
       "      <td>7.047873</td>\n",
       "      <td>0.000249</td>\n",
       "      <td>150</td>\n",
       "      <td>73.853333</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.490926</td>\n",
       "      <td>3</td>\n",
       "      <td>82</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Downt</td>\n",
       "      <td>Dont know</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>7.047838</td>\n",
       "      <td>4.097123</td>\n",
       "      <td>65</td>\n",
       "      <td>74.338462</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.415385</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Downt</td>\n",
       "      <td>Chau Down</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>False</td>\n",
       "      <td>7.047823</td>\n",
       "      <td>5.818265</td>\n",
       "      <td>42</td>\n",
       "      <td>75.285714</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.517207</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Downt</td>\n",
       "      <td>Double Down Saloon</td>\n",
       "      <td>5</td>\n",
       "      <td>18</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>False</td>\n",
       "      <td>6.029442</td>\n",
       "      <td>2.301789</td>\n",
       "      <td>51</td>\n",
       "      <td>75.019608</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.607843</td>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>EastRi</td>\n",
       "      <td>Kasuri</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>4.749061</td>\n",
       "      <td>0.002035</td>\n",
       "      <td>3</td>\n",
       "      <td>84.333333</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>EastRi</td>\n",
       "      <td>Eastern</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>True</td>\n",
       "      <td>4.747308</td>\n",
       "      <td>166.125773</td>\n",
       "      <td>6</td>\n",
       "      <td>68.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>EastR</td>\n",
       "      <td>East Wok</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>True</td>\n",
       "      <td>4.434819</td>\n",
       "      <td>143.574125</td>\n",
       "      <td>6</td>\n",
       "      <td>66.833333</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.166667</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Elk La</td>\n",
       "      <td>La La Taqueria</td>\n",
       "      <td>6</td>\n",
       "      <td>14</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>False</td>\n",
       "      <td>6.982998</td>\n",
       "      <td>310.706174</td>\n",
       "      <td>3</td>\n",
       "      <td>182.333333</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.321908</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Elk La</td>\n",
       "      <td>Oh La La</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>False</td>\n",
       "      <td>6.982845</td>\n",
       "      <td>325.914534</td>\n",
       "      <td>139</td>\n",
       "      <td>65.323741</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.079137</td>\n",
       "      <td>1</td>\n",
       "      <td>40</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Elk La</td>\n",
       "      <td>La La Land</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>False</td>\n",
       "      <td>6.982682</td>\n",
       "      <td>342.240316</td>\n",
       "      <td>5</td>\n",
       "      <td>63.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.600000</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Empire Sta</td>\n",
       "      <td>Empire Auto Spa</td>\n",
       "      <td>10</td>\n",
       "      <td>15</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>True</td>\n",
       "      <td>9.497075</td>\n",
       "      <td>0.000518</td>\n",
       "      <td>14</td>\n",
       "      <td>63.928571</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.142857</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Empire Sta</td>\n",
       "      <td>Empire</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>True</td>\n",
       "      <td>9.207912</td>\n",
       "      <td>1.332742</td>\n",
       "      <td>4</td>\n",
       "      <td>74.750000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.250000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Enla</td>\n",
       "      <td>Ella</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>9.932207</td>\n",
       "      <td>0.001129</td>\n",
       "      <td>31</td>\n",
       "      <td>76.258065</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.322581</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Enla</td>\n",
       "      <td>Ella Baker School</td>\n",
       "      <td>4</td>\n",
       "      <td>17</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>7.053116</td>\n",
       "      <td>2.070831</td>\n",
       "      <td>48</td>\n",
       "      <td>67.354167</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Esty</td>\n",
       "      <td>Zesty Pizzeria &amp; Salumeria</td>\n",
       "      <td>4</td>\n",
       "      <td>26</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>7.417501</td>\n",
       "      <td>73.291759</td>\n",
       "      <td>1254</td>\n",
       "      <td>65.259171</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.523361</td>\n",
       "      <td>1</td>\n",
       "      <td>425</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Esty</td>\n",
       "      <td>Kool-est Shoes</td>\n",
       "      <td>4</td>\n",
       "      <td>14</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>6.601116</td>\n",
       "      <td>98.998907</td>\n",
       "      <td>36</td>\n",
       "      <td>63.027778</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.055556</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        query                    document query_length document_length  \\\n",
       "0   Dix/Adler             Johnathan Adler            9              15   \n",
       "1   Dix/Adler              Jonathan Adler            9              14   \n",
       "0       Downt                   Up & Down            5               9   \n",
       "1       Downt                   Dont know            5               9   \n",
       "2       Downt                   Chau Down            5               9   \n",
       "3       Downt          Double Down Saloon            5              18   \n",
       "0      EastRi                      Kasuri            6               6   \n",
       "1      EastRi                     Eastern            6               7   \n",
       "0       EastR                    East Wok            5               8   \n",
       "0      Elk La              La La Taqueria            6              14   \n",
       "1      Elk La                    Oh La La            6               8   \n",
       "2      Elk La                  La La Land            6              10   \n",
       "0  Empire Sta             Empire Auto Spa           10              15   \n",
       "1  Empire Sta                      Empire           10               6   \n",
       "0        Enla                        Ella            4               4   \n",
       "1        Enla           Ella Baker School            4              17   \n",
       "0        Esty  Zesty Pizzeria & Salumeria            4              26   \n",
       "1        Esty              Kool-est Shoes            4              14   \n",
       "\n",
       "   jaccard_entire  sub_jaccard prefix_match  elasticsearch_score    distance  \\\n",
       "0        0.000000     0.000000        False            10.596428  372.269962   \n",
       "1        0.000000     0.000000        False            10.596423  372.302677   \n",
       "0        0.000000     0.333333        False             7.047873    0.000249   \n",
       "1        0.000000     0.000000        False             7.047838    4.097123   \n",
       "2        0.000000     0.500000        False             7.047823    5.818265   \n",
       "3        0.000000     0.333333        False             6.029442    2.301789   \n",
       "0        0.000000     0.000000        False             4.749061    0.002035   \n",
       "1        0.000000     1.000000         True             4.747308  166.125773   \n",
       "0        0.000000     0.500000         True             4.434819  143.574125   \n",
       "0        0.333333     0.333333        False             6.982998  310.706174   \n",
       "1        0.333333     0.333333        False             6.982845  325.914534   \n",
       "2        0.333333     0.333333        False             6.982682  342.240316   \n",
       "0        0.250000     0.250000         True             9.497075    0.000518   \n",
       "1        0.500000     0.500000         True             9.207912    1.332742   \n",
       "0        0.000000     0.000000        False             9.932207    0.001129   \n",
       "1        0.000000     0.000000        False             7.053116    2.070831   \n",
       "0        0.000000     0.000000        False             7.417501   73.291759   \n",
       "1        0.000000     0.000000        False             6.601116   98.998907   \n",
       "\n",
       "  tweets_count  tweets_average_length replies_count retweets_count  \\\n",
       "0           17              75.117647             0              0   \n",
       "1           30              76.233333             0              0   \n",
       "0          150              73.853333             0              0   \n",
       "1           65              74.338462             0              0   \n",
       "2           42              75.285714             0              0   \n",
       "3           51              75.019608             0              0   \n",
       "0            3              84.333333             0              0   \n",
       "1            6              68.000000             0              0   \n",
       "0            6              66.833333             0              0   \n",
       "0            3             182.333333             0              0   \n",
       "1          139              65.323741             0              0   \n",
       "2            5              63.000000             0              0   \n",
       "0           14              63.928571             0              0   \n",
       "1            4              74.750000             0              0   \n",
       "0           31              76.258065             0              0   \n",
       "1           48              67.354167             0              0   \n",
       "0         1254              65.259171             0              0   \n",
       "1           36              63.027778             0              0   \n",
       "\n",
       "  likes_count  popularity hashtags mentions  label  \n",
       "0           0    1.512406        0       10    5.0  \n",
       "1           0    1.612857        0       22    4.0  \n",
       "0           0    1.490926        3       82    5.0  \n",
       "1           0    1.415385        0       32    2.0  \n",
       "2           0    1.517207        0       17    4.0  \n",
       "3           0    1.607843        0       36    4.0  \n",
       "0           0    1.333333        0        2    4.0  \n",
       "1           0    1.500000        0        4    5.0  \n",
       "0           0    1.166667        0        6    5.0  \n",
       "0           0    1.321908        0        1    5.0  \n",
       "1           0    2.079137        1       40    4.0  \n",
       "2           0    1.600000        0        5    3.0  \n",
       "0           0    1.142857        0        3    4.0  \n",
       "1           0    1.250000        0        1    5.0  \n",
       "0           0    1.322581        0        9    5.0  \n",
       "1           0    1.333333        0       25    4.0  \n",
       "0           0    1.523361        1      425    5.0  \n",
       "1           0    1.055556        0        0    4.0  "
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data.to_csv('/Users/emadarmiti/Desktop/cap-s5/places_ranking/row_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
