{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import pymongo\n",
    "import dns\n",
    "import json\n",
    "from nltk.sentiment import SentimentAnalyzer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### read the query-doc JSON file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the directory path\n",
    "path_to_json = '/Users/emadarmiti/Desktop/cap-s5/places_ranking/es_qureries/'\n",
    "\n",
    "# define the query-document json file \n",
    "query_doc = json.loads('{}')\n",
    "\n",
    "# get all json files that exist in the directory\n",
    "for file_path in os.listdir(path_to_json):\n",
    "    \n",
    "    if file_path.endswith('.json'):\n",
    "        \n",
    "        # open the json file \n",
    "        with open(os.path.join(path_to_json,file_path)) as json_file:\n",
    "            \n",
    "            # append the json file, to get all of them in on json variable\n",
    "            query_doc.update(json.load(json_file))\n",
    "                       \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23079"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(query_doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### connect to MongoDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the mongoDB endpoint\n",
    "mongoDB = \"mongodb://rama:rama@cluster0-shard-00-00.xlj8q.mongodb.net:27017,cluster0-shard-00-01.xlj8q.mongodb.net:27017,cluster0-shard-00-02.xlj8q.mongodb.net:27017/tweets?ssl=true&replicaSet=atlas-yi054u-shard-0&authSource=admin&retryWrites=true&w=majority\"\n",
    "        \n",
    "# defien mongodb client\n",
    "mongoDB_client = pymongo.MongoClient(mongoDB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the database\n",
    "tweets_database = mongoDB_client['tweets']\n",
    "\n",
    "# get the collection\n",
    "tweets_collection = tweets_database['tweets2018']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### find the tweets that near to the documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_tweets_near_place(coordinates):\n",
    "\n",
    "    \n",
    "    # define the body of the query\n",
    "    myquery =  [\n",
    "      { \"$geoNear\": {\n",
    "          \n",
    "         \"near\": { \"type\": \"Point\", \"coordinates\": coordinates },\n",
    "         \"distanceField\": \"place.coordinates\",\n",
    "         \"maxDistance\": 100\n",
    "         }\n",
    "       }\n",
    "    ,{  \"$group\": { \"_id\": None,\n",
    "                   \"tweets_count\": { \"$sum\": 1 },\n",
    "                   \"replies_count\": { \"$sum\": \"replies_count\"},\n",
    "                   \"retweets_count\": { \"$sum\": \"retweets_count\"}, \n",
    "                   \"likes_count\": { \"$sum\": \"likes_count\"}\n",
    "                  } }]\n",
    "\n",
    "    # send the query and return the results\n",
    "    return list(tweets_collection.aggregate(myquery))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the result dictt\n",
    "tweets_query_doc = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "# go over each query-doc and use the previous function to get the tweets from the MongoDB\n",
    "for query in list(query_doc.keys()):\n",
    "    \n",
    "    doc_tweets = {\"query\":query}\n",
    "    \n",
    "    for doc in query_doc[query]:\n",
    "        \n",
    "        # slice the location of the document\n",
    "        coordinates = list(doc['_source']['location'].values())\n",
    "        \n",
    "        # get the tweets\n",
    "        tweets = find_tweets_near_place(coordinates)\n",
    "        \n",
    "        # neglect the doc that don't have tweets\n",
    "        if len(tweets):\n",
    "            doc_tweets['elasticsearch_score'] = doc['_score']\n",
    "            doc_tweets.update({\"document\" : doc['_source']['name'], \n",
    "                               \"location\": doc['_source']['location']})\n",
    "            doc_tweets.update(tweets[0])\n",
    "    \n",
    "    # neglect the queries that don't have documents with tweets\n",
    "    if \"document\" in doc_tweets:\n",
    "        tweets_query_doc.append(doc_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query</th>\n",
       "      <th>elasticsearch_score</th>\n",
       "      <th>document</th>\n",
       "      <th>_id</th>\n",
       "      <th>tweets_count</th>\n",
       "      <th>replies_count</th>\n",
       "      <th>retweets_count</th>\n",
       "      <th>likes_count</th>\n",
       "      <th>location.lat</th>\n",
       "      <th>location.lon</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dix/Adler</td>\n",
       "      <td>10.596423</td>\n",
       "      <td>Jonathan Adler</td>\n",
       "      <td>None</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40.779032</td>\n",
       "      <td>-73.977859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Downt</td>\n",
       "      <td>6.029442</td>\n",
       "      <td>Double Down Saloon</td>\n",
       "      <td>None</td>\n",
       "      <td>51</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40.722569</td>\n",
       "      <td>-73.985846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>EastRi</td>\n",
       "      <td>4.747308</td>\n",
       "      <td>Eastern</td>\n",
       "      <td>None</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40.765673</td>\n",
       "      <td>-73.930822</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       query  elasticsearch_score            document   _id  tweets_count  \\\n",
       "0  Dix/Adler            10.596423      Jonathan Adler  None            30   \n",
       "1      Downt             6.029442  Double Down Saloon  None            51   \n",
       "2     EastRi             4.747308             Eastern  None             6   \n",
       "\n",
       "   replies_count  retweets_count  likes_count  location.lat  location.lon  \n",
       "0              0               0            0     40.779032    -73.977859  \n",
       "1              0               0            0     40.722569    -73.985846  \n",
       "2              0               0            0     40.765673    -73.930822  "
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.json_normalize(tweets_query_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('/Users/emadarmiti/Desktop/cap-s5/places_ranking/row_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### build the dataframe "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tf-idf?\n",
    "# should we delete non tweets doc?\n",
    "# why just two featrues in labeling?\n",
    "# hashtags\n",
    "# query/document length\n",
    "# nlp\n",
    "# tweets average length\n",
    "# mentions - boolean\n",
    "## label = nlp + distance + elasicsearch + tweets?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
