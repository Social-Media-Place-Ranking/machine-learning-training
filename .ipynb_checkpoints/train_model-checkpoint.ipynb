{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import pymongo\n",
    "import dns\n",
    "import json\n",
    "from nltk.sentiment import SentimentAnalyzer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### read the query-doc JSON file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the directory path\n",
    "path_to_json = '/Users/emadarmiti/Desktop/cap-s5/places_ranking/es_qureries/'\n",
    "\n",
    "# define the query-document json file \n",
    "query_doc = json.loads('{}')\n",
    "\n",
    "# get all json files that exist in the directory\n",
    "for file_path in os.listdir(path_to_json):\n",
    "    \n",
    "    if file_path.endswith('.json'):\n",
    "        \n",
    "        # open the json file \n",
    "        with open(os.path.join(path_to_json,file_path)) as json_file:\n",
    "            \n",
    "            # append the json file, to get all of them in on json variable\n",
    "            query_doc.update(json.load(json_file))\n",
    "                       \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23079"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(query_doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### connect to MongoDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the mongoDB endpoint\n",
    "mongoDB = \"mongodb://rama:rama@cluster0-shard-00-00.xlj8q.mongodb.net:27017,cluster0-shard-00-01.xlj8q.mongodb.net:27017,cluster0-shard-00-02.xlj8q.mongodb.net:27017/tweets?ssl=true&replicaSet=atlas-yi054u-shard-0&authSource=admin&retryWrites=true&w=majority\"\n",
    "        \n",
    "# defien mongodb client\n",
    "mongoDB_client = pymongo.MongoClient(mongoDB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the database\n",
    "tweets_database = mongoDB_client['tweets']\n",
    "\n",
    "# get the collection\n",
    "tweets_collection = tweets_database['tweets2018']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### find the tweets that near to the documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_tweets_near_place(coordinates):\n",
    "    \"\"\"\n",
    "    This function is used for retrieving tweets in 100 m range around the document location \n",
    "    \n",
    "    [params] : coordinates : the document location \n",
    "    \n",
    "    [return] : list of tweets\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    # define the body of the query\n",
    "    myquery = {\n",
    "       \"place.coordinates\": {\n",
    "           \"$near\": {\n",
    "           \"$geometry\": {\n",
    "              \"type\": \"Point\" ,\n",
    "              \"coordinates\": coordinates\n",
    "           },\n",
    "           \"$maxDistance\": 100,\n",
    "           \"$minDistance\": 0\n",
    "         }\n",
    "       }\n",
    "    }\n",
    "\n",
    "    # send the query and return the results\n",
    "    return list(tweets_collection.find(myquery))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the result dictt\n",
    "tweets_query_doc = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# go over each query-doc and use the previous function to get the tweets from the MongoDB\n",
    "for query in list(query_doc.keys()):\n",
    "    \n",
    "    doc_tweets = []\n",
    "    \n",
    "    for doc in query_doc[query]:\n",
    "        \n",
    "        # slice the location of the document\n",
    "        coordinates = list(doc['_source']['location'].values())\n",
    "        \n",
    "        # get the tweets\n",
    "        tweets = find_tweets_near_place(coordinates)\n",
    "        \n",
    "        # delete the mongoDB id which is an object\n",
    "        for index in range(len(tweets)):\n",
    "            tweets[index].pop('_id',None)\n",
    "            tweets[index]['elasticsearch_score'] = doc['_score']\n",
    "        \n",
    "        # neglect the doc that don't have tweets\n",
    "        if bool(tweets):\n",
    "            \n",
    "            doc_tweets.append({\"name\" : doc['_source']['name'], \n",
    "                               \"location\": doc['_source']['location'],\n",
    "                               \"tweets\":tweets })\n",
    "    \n",
    "    # neglect the queries that don't have documents with tweets\n",
    "    if bool(doc_tweets) :\n",
    "        tweets_query_doc[query] = doc_tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### save the query-doc-tweets into a JSON file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dict_to_json(dictionary, outfile_path):\n",
    "    \"\"\"\n",
    "    This function is used for storing a dict into json file \n",
    "    [params] : dictionary : the data\n",
    "    [params] : outfile_path : the path of the out json file\n",
    "    \"\"\"\n",
    "    \n",
    "    with open(outfile_path, \"w\") as outfile:  \n",
    "        json.dump(dictionary, outfile) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# define the outfile path\n",
    "json_outfile_path = \"/Users/emadarmiti/Desktop/cap-s5/places_ranking/tweets_query_doc.json\"\n",
    "\n",
    "# call the function to store the data to the json\n",
    "dict_to_json(tweets_query_doc, json_outfile_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### build the dataframe "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the keys to slice from tweets\n",
    "KEYS = ['query', 'document', \"time\", \"tweet\", \"replies_count\",\n",
    "        \"retweets_count\", \"likes_count\",\"elasticsearch_score\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an empty dataframe \n",
    "data = pd.DataFrame(columns = KEYS) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query</th>\n",
       "      <th>document</th>\n",
       "      <th>time</th>\n",
       "      <th>tweet</th>\n",
       "      <th>replies_count</th>\n",
       "      <th>retweets_count</th>\n",
       "      <th>likes_count</th>\n",
       "      <th>elasticsearch_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [query, document, time, tweet, replies_count, retweets_count, likes_count, elasticsearch_score]\n",
       "Index: []"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for query in list(tweets_query_doc.keys()):\n",
    "    \n",
    "    result = {KEYS[0] : query}\n",
    "    \n",
    "    for doc in list(tweets_query_doc[query].keys()):\n",
    "        \n",
    "        result[KEYS[1]] = doc\n",
    "        \n",
    "        for tweet in tweets_query_doc[query][doc]:\n",
    "            \n",
    "            for key in KEYS[2:]:\n",
    "                \n",
    "                result[key] = tweet[key]\n",
    "                \n",
    "            data = data.append(result, ignore_index=True)\n",
    "            \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query</th>\n",
       "      <th>document</th>\n",
       "      <th>time</th>\n",
       "      <th>tweet</th>\n",
       "      <th>replies_count</th>\n",
       "      <th>retweets_count</th>\n",
       "      <th>likes_count</th>\n",
       "      <th>elasticsearch_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dix/Adler</td>\n",
       "      <td>Johnathan Adler</td>\n",
       "      <td>19:44:21</td>\n",
       "      <td>I'm at Neofytos in New York, NY  https://t.co/...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10.596428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dix/Adler</td>\n",
       "      <td>Johnathan Adler</td>\n",
       "      <td>20:47:04</td>\n",
       "      <td>I'm at Caffe Grazie in New York, NY  https://t...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10.596428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dix/Adler</td>\n",
       "      <td>Johnathan Adler</td>\n",
       "      <td>17:50:53</td>\n",
       "      <td>I'm at Starbucks Reserve in New York, NY w/ @p...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10.596428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dix/Adler</td>\n",
       "      <td>Johnathan Adler</td>\n",
       "      <td>16:44:09</td>\n",
       "      <td>I'm at Starbucks Reserve in New York, NY  http...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10.596428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Dix/Adler</td>\n",
       "      <td>Johnathan Adler</td>\n",
       "      <td>01:52:18</td>\n",
       "      <td>I'm at Starbucks Reserve in New York, NY  http...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10.596428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1913</th>\n",
       "      <td>Esty</td>\n",
       "      <td>Kool-est Shoes</td>\n",
       "      <td>12:25:53</td>\n",
       "      <td>I'm at LA Fitness in Staten Island, NY  https:...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6.601116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1914</th>\n",
       "      <td>Esty</td>\n",
       "      <td>Kool-est Shoes</td>\n",
       "      <td>12:27:51</td>\n",
       "      <td>I'm at LA Fitness in Staten Island, NY  https:...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6.601116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1915</th>\n",
       "      <td>Esty</td>\n",
       "      <td>Kool-est Shoes</td>\n",
       "      <td>12:25:31</td>\n",
       "      <td>I'm at LA Fitness in Staten Island, NY  https:...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6.601116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1916</th>\n",
       "      <td>Esty</td>\n",
       "      <td>Kool-est Shoes</td>\n",
       "      <td>12:16:39</td>\n",
       "      <td>I'm at LA Fitness in Staten Island, NY  https:...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6.601116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1917</th>\n",
       "      <td>Esty</td>\n",
       "      <td>Kool-est Shoes</td>\n",
       "      <td>12:31:10</td>\n",
       "      <td>I'm at LA Fitness in Staten Island, NY  https:...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6.601116</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1918 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          query         document      time  \\\n",
       "0     Dix/Adler  Johnathan Adler  19:44:21   \n",
       "1     Dix/Adler  Johnathan Adler  20:47:04   \n",
       "2     Dix/Adler  Johnathan Adler  17:50:53   \n",
       "3     Dix/Adler  Johnathan Adler  16:44:09   \n",
       "4     Dix/Adler  Johnathan Adler  01:52:18   \n",
       "...         ...              ...       ...   \n",
       "1913       Esty   Kool-est Shoes  12:25:53   \n",
       "1914       Esty   Kool-est Shoes  12:27:51   \n",
       "1915       Esty   Kool-est Shoes  12:25:31   \n",
       "1916       Esty   Kool-est Shoes  12:16:39   \n",
       "1917       Esty   Kool-est Shoes  12:31:10   \n",
       "\n",
       "                                                  tweet replies_count  \\\n",
       "0     I'm at Neofytos in New York, NY  https://t.co/...             0   \n",
       "1     I'm at Caffe Grazie in New York, NY  https://t...             0   \n",
       "2     I'm at Starbucks Reserve in New York, NY w/ @p...             0   \n",
       "3     I'm at Starbucks Reserve in New York, NY  http...             0   \n",
       "4     I'm at Starbucks Reserve in New York, NY  http...             0   \n",
       "...                                                 ...           ...   \n",
       "1913  I'm at LA Fitness in Staten Island, NY  https:...             0   \n",
       "1914  I'm at LA Fitness in Staten Island, NY  https:...             0   \n",
       "1915  I'm at LA Fitness in Staten Island, NY  https:...             1   \n",
       "1916  I'm at LA Fitness in Staten Island, NY  https:...             0   \n",
       "1917  I'm at LA Fitness in Staten Island, NY  https:...             0   \n",
       "\n",
       "     retweets_count likes_count  elasticsearch_score  \n",
       "0                 0           0            10.596428  \n",
       "1                 0           0            10.596428  \n",
       "2                 0           0            10.596428  \n",
       "3                 0           0            10.596428  \n",
       "4                 0           0            10.596428  \n",
       "...             ...         ...                  ...  \n",
       "1913              0           0             6.601116  \n",
       "1914              0           0             6.601116  \n",
       "1915              0           0             6.601116  \n",
       "1916              0           0             6.601116  \n",
       "1917              0           0             6.601116  \n",
       "\n",
       "[1918 rows x 8 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query</th>\n",
       "      <th>document</th>\n",
       "      <th>tweet</th>\n",
       "      <th>replies_count</th>\n",
       "      <th>likes_count</th>\n",
       "      <th>retweets_count</th>\n",
       "      <th>elasticsearch_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dix/Adler</td>\n",
       "      <td>Johnathan Adler</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>10.596428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dix/Adler</td>\n",
       "      <td>Jonathan Adler</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>10.596423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Downt</td>\n",
       "      <td>Chau Down</td>\n",
       "      <td>43</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>7.047823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Downt</td>\n",
       "      <td>Dont know</td>\n",
       "      <td>66</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>7.047838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Downt</td>\n",
       "      <td>Double Down Saloon</td>\n",
       "      <td>51</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>6.029442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Downt</td>\n",
       "      <td>Up &amp; Down</td>\n",
       "      <td>151</td>\n",
       "      <td>5</td>\n",
       "      <td>57</td>\n",
       "      <td>2</td>\n",
       "      <td>7.047873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>EastR</td>\n",
       "      <td>East Wok</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4.434819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>EastRi</td>\n",
       "      <td>Eastern</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.747308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>EastRi</td>\n",
       "      <td>Kasuri</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4.749061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Elk La</td>\n",
       "      <td>La La Land</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6.982682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Elk La</td>\n",
       "      <td>La La Taqueria</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>6.982998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Elk La</td>\n",
       "      <td>Oh La La</td>\n",
       "      <td>139</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>6.982845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Empire Sta</td>\n",
       "      <td>Empire</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>9.207912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Empire Sta</td>\n",
       "      <td>Empire Auto Spa</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>9.497075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Empire Sta</td>\n",
       "      <td>Empire Visionworks</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.649227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Enla</td>\n",
       "      <td>Ella</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>9.932207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Enla</td>\n",
       "      <td>Ella Baker School</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7.053116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Esty</td>\n",
       "      <td>Kool-est Shoes</td>\n",
       "      <td>36</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6.601116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Esty</td>\n",
       "      <td>Zesty Pizzeria &amp; Salumeria</td>\n",
       "      <td>1262</td>\n",
       "      <td>8</td>\n",
       "      <td>27</td>\n",
       "      <td>2</td>\n",
       "      <td>7.417501</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         query                    document  tweet  replies_count  likes_count  \\\n",
       "0    Dix/Adler             Johnathan Adler     17              0            2   \n",
       "1    Dix/Adler              Jonathan Adler     30              0            3   \n",
       "2        Downt                   Chau Down     43              7            5   \n",
       "3        Downt                   Dont know     66              1            6   \n",
       "4        Downt          Double Down Saloon     51              3           13   \n",
       "5        Downt                   Up & Down    151              5           57   \n",
       "6        EastR                    East Wok      6              0            4   \n",
       "7       EastRi                     Eastern      6              0            0   \n",
       "8       EastRi                      Kasuri      3              2            1   \n",
       "9       Elk La                  La La Land      5              0            0   \n",
       "10      Elk La              La La Taqueria      3              1            4   \n",
       "11      Elk La                    Oh La La    139              0           25   \n",
       "12  Empire Sta                      Empire      4              0            2   \n",
       "13  Empire Sta             Empire Auto Spa     14              0            4   \n",
       "14  Empire Sta          Empire Visionworks      1              0            0   \n",
       "15        Enla                        Ella     31              0            6   \n",
       "16        Enla           Ella Baker School     50              0            1   \n",
       "17        Esty              Kool-est Shoes     36              1            1   \n",
       "18        Esty  Zesty Pizzeria & Salumeria   1262              8           27   \n",
       "\n",
       "    retweets_count  elasticsearch_score  \n",
       "0                0            10.596428  \n",
       "1                0            10.596423  \n",
       "2                1             7.047823  \n",
       "3                0             7.047838  \n",
       "4                1             6.029442  \n",
       "5                2             7.047873  \n",
       "6                0             4.434819  \n",
       "7                0             4.747308  \n",
       "8                0             4.749061  \n",
       "9                0             6.982682  \n",
       "10               0             6.982998  \n",
       "11               0             6.982845  \n",
       "12               0             9.207912  \n",
       "13               4             9.497075  \n",
       "14               0             7.649227  \n",
       "15               0             9.932207  \n",
       "16               1             7.053116  \n",
       "17               0             6.601116  \n",
       "18               2             7.417501  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.groupby(['query', 'document']).agg({'tweet': 'count', 'replies_count': 'sum', 'likes_count': 'sum'\n",
    "                                        ,'retweets_count': 'sum', 'elasticsearch_score': 'first'}).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data.to_csv('/Users/emadarmiti/Desktop/cap-s5/places_ranking/training_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
